{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8dcf79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13a74da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "#importing data from mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "737ea29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#loading data from mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66e93528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f2aec1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee547f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5493c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f64cd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c85a3814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9326555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9c89be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Defining layer status\n",
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b1dae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding layers config\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# To add new layer \n",
    "# network.add(layers.Dense(256, activation='relu')\n",
    "\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Sequential means stacks of layers\n",
    "# Dense layer in which each neuron node is connected to other nureon node\n",
    "# The input shape in layer is the size of data which is going to process in layer in 1d Vector\n",
    "# softmax is function which is for multi classification\n",
    "# Sigmiod is function which is for binary classification\n",
    "# Relu is function which is for regressiuon classification\n",
    "# First layer is called input layer\n",
    "# All Layer is between first and last are called hidden layers\n",
    "# Last Layer is called output layer\n",
    "# To add new layer the best way is to use 2 power formula better not to use odd \n",
    "# Note the data is currently soo much refined but if the data is not refined so in this case\n",
    "# We will improve our model by adjusting layer value and adding more layers and etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ea5cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN can process numbers, text, images, videos, voices, another data it is general network\n",
    "# But later with moderation developers designs specialized netowrks for each works\n",
    "# Images -> CNN\n",
    "# Text -> RNN\n",
    "# Generation from scratch -> GNN\n",
    "\n",
    "# These are for improving accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aeeb901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compile the network\n",
    "# First provide optimizer which adjust weight to get accuracy\n",
    "# Loss function means which provide the loss value\n",
    "# Metrics means the result in from we want to see\n",
    "\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "138b00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data first\n",
    "# convert the data into correct shape 60000 columns and 784 data - rows\n",
    "\n",
    "# Because we have said model layer that the data will have a vector of 784 rows \n",
    "# But currently data is in 28*28 form which is un-acceptable. So we have to reshape it\n",
    "\n",
    "# before reshaping images \n",
    "# train_images.shape\n",
    "\n",
    "# now reshaping image and checking shape\n",
    "# train_images[0].reshape(784).shape\n",
    "\n",
    "# but the issue is this is only for shaping single image but we want to shape all images\n",
    "# in this case we will \n",
    "\n",
    "train_images = train_images.reshape((60000,784))\n",
    "# to convert into decimal we will use float to scale down value cuz value are to big\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "# to convert into decimal we will use float to scale down value cuz value are to big\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf661c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "# Basically here we are converting labels to categories \n",
    "# Which will be stored inside a vector\n",
    "# It will use one hot encoding to convert labels to categories\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27b97417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 3s 16ms/step - loss: 0.3981 - accuracy: 0.8874\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 2s 16ms/step - loss: 0.1734 - accuracy: 0.9502\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.1175 - accuracy: 0.9656\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.0870 - accuracy: 0.9746\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.0681 - accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b00272a0b0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now training model\n",
    "#  1) Provide data to train\n",
    "#  2 Provide label of training\n",
    "#  3 Provide epoch size which means x time to train model\n",
    "#  4 Provide batch size which means each time train with 512 images batch (goes to ram and bring image)\n",
    "# This model will use back propagation algorithm \n",
    "\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "719e7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in above case we got the accuracy of 0.9799 which is good enough but in this case\n",
    "# we have only trained data accuracy so we will check is model fit with test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f62b783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy from test data\n",
    "# Provide 1 test images and 2 test lables \n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "01a9a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in this case we have approx same value of accuracy so our model is fit and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "82f7208d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now converting Image from 1d array to image \n",
    "\n",
    "digit = train_images[5].reshape(28, 28)*255\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093a097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
