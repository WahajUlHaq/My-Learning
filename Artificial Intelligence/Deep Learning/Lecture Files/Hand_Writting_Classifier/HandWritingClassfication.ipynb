{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8dcf79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "13a74da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "#importing data from mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "737ea29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#loading data from mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9c89be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Defining layer status\n",
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2b1dae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding layers config\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# To add new layer \n",
    "# network.add(layers.Dense(256, activation='relu')\n",
    "\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# Sequential means stacks of layers\n",
    "# Dense layer in which each neuron node is connected to other nureon node\n",
    "# The input shape in layer is the size of data which is going to process in layer in 1d Vector\n",
    "# softmax is function which is for multi classification\n",
    "# Sigmiod is function which is for binary classification\n",
    "# Relu is function which is for regressiuon classification\n",
    "# First layer is called input layer\n",
    "# All Layer is between first and last are called hidden layers\n",
    "# Last Layer is called output layer\n",
    "# To add new layer the best way is to use 2 power formula better not to use odd \n",
    "# Note the data is currently soo much refined but if the data is not refined so in this case\n",
    "# We will improve our model by adjusting layer value and adding more layers and etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7ea5cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN can process numbers, text, images, videos, voices, another data it is general network\n",
    "# But later with moderation developers designs specialized netowrks for each works\n",
    "# Images -> CNN\n",
    "# Text -> RNN\n",
    "# Generation from scratch -> GNN\n",
    "\n",
    "# These are for improving accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aeeb901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compile the network\n",
    "# First provide optimizer which adjust weight to get accuracy\n",
    "# Loss function means which provide the loss value\n",
    "# Metrics means the result in from we want to see\n",
    "\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "138b00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data first\n",
    "# convert the data into correct shape 60000 columns and 784 data - rows\n",
    "\n",
    "# Because we have said model layer that the data will have a vector of 784 rows \n",
    "# But currently data is in 28*28 form which is un-acceptable. So we have to reshape it\n",
    "\n",
    "# before reshaping images \n",
    "# train_images.shape\n",
    "\n",
    "# now reshaping image and checking shape\n",
    "# train_images[0].reshape(784).shape\n",
    "\n",
    "# but the issue is this is only for shaping single image but we want to shape all images\n",
    "# in this case we will \n",
    "\n",
    "train_images = train_images.reshape((60000,784))\n",
    "# to convert into decimal we will use float to scale down value cuz value are to big\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "# to convert into decimal we will use float to scale down value cuz value are to big\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cf661c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "# Basically here we are converting labels to categories \n",
    "# Which will be stored inside a vector\n",
    "# It will use one hot encoding to convert labels to categories\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "27b97417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 2s 15ms/step - loss: 0.3967 - accuracy: 0.8874\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 2s 15ms/step - loss: 0.1762 - accuracy: 0.9481\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 2s 16ms/step - loss: 0.1215 - accuracy: 0.9651\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 2s 16ms/step - loss: 0.0906 - accuracy: 0.9733\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 2s 16ms/step - loss: 0.0690 - accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291d3725e70>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now training model\n",
    "#  1) Provide data to train\n",
    "#  2 Provide label of training\n",
    "#  3 Provide epoch size which means x time to train model\n",
    "#  4 Provide batch size which means each time train with 512 images batch (goes to ram and bring image)\n",
    "# This model will use back propagation algorithm \n",
    "\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "719e7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in above case we got the accuracy of 0.9799 which is good enough but in this case\n",
    "# we have only trained data accuracy so we will check is model fit with test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4f62b783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9720\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy from test data\n",
    "# Provide 1 test images and 2 test lables \n",
    "\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "01a9a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in this case we have approx same value of accuracy so our model is fit and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "82f7208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now converting Image from 1d array to image \n",
    "\n",
    "# digit = train_images[16].reshape(28, 28)*255\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# to view image\n",
    "# plt.imshow(digit, cmap=plt.cm.gray)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fc96af8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: handwrittenPrediction.sav\\assets\n"
     ]
    }
   ],
   "source": [
    "# Now saving our model to server using network\n",
    "# This uses .sav extension\n",
    "\n",
    "network.save(\"handwrittenPrediction.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c0f71da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Now making model able to predict any image\n",
    "# For that we are using tensorflow image reader\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Now our model is saved into server and is ready to be used any where so we can use it like\n",
    "# exporting keras from tensor flow \n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# now exporting the model which we saved / created using keras\n",
    "\n",
    "handwritting_model  = keras.models.load_model(\"handwrittenPrediction.sav\")\n",
    "\n",
    "\n",
    "def uploadImageAndPredict (imagePath): \n",
    "    # Now loading the image from user and using it\n",
    "    # first we have to pass the image path \n",
    "    # the target size will be size in which model will read the image \n",
    "    # Since our model is using gray scale images so we have to pass image converted to grayscale\n",
    "    # Since gray scale mode is deprecatted so we can also use color_mode = grayscale\n",
    "\n",
    "    image_uploaded = image.load_img(imagePath ,target_size=(28,28), color_mode='grayscale')\n",
    "\n",
    "    # now convert the image to array so that we can send it to model\n",
    "    # here we will use a function exported from image library\n",
    "    # we will pass uploaded image to it so it will convert it into an array\n",
    "\n",
    "    array_of_image_uploaded = image.img_to_array(image_uploaded)\n",
    "\n",
    "    # Now we have to reshape this image into format that model expect (1, 784)\n",
    "    # 1 = quantity of image like 60000 is quantity of image so we can use 60000 over 1\n",
    "    # 784 is 28*28 which means dimension of image converted into 2d array\n",
    "\n",
    "    array_of_image_uploaded = array_of_image_uploaded.reshape(1, 784)\n",
    "    \n",
    "    # Converting to float\n",
    "    \n",
    "    array_of_image_uploaded = array_of_image_uploaded.astype(\"float32\") / 255\n",
    "    \n",
    "    # Now finding probablity of uploaded model\n",
    "\n",
    "    probablity = handwritting_model.predict(array_of_image_uploaded)\n",
    "    \n",
    "    # Getting the max value of probality from the value recieved above from model\n",
    "\n",
    "    result_prediction = probablity.argmax()\n",
    "    \n",
    "    return result_prediction\n",
    "    \n",
    "# calling function\n",
    "prediction = uploadImageAndPredict(\"imagesToTest/2.jpg\")\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0a6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705ff36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
